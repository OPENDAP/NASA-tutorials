{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e4a86e9-cd1d-445b-a7c9-89b2466414d9",
   "metadata": {},
   "source": [
    "<span style='color:#009999'> <span style='font-family:serif'> <font size=\"15\"> **Using Earthaccess for access data via Hyrax's DMR++**<span style='color:#0066cc'> \n",
    "\n",
    "\n",
    "\n",
    "<span style='color:#ff6666'><font size=\"5\">**Requirements**\n",
    "1. <font size=\"3\"><span style='color:Black'> An active EDL account.\n",
    "\n",
    "<font size=\"3\"><span style='color:Black'> `earthaccess` has their own way to authenticate that makes use of your EDL logging information.\n",
    "\n",
    " <span style='color:#ff6666'><font size=\"5\"> **OPeNDAP, DMR++ and VirtualiZarr**\n",
    "\n",
    "\n",
    "<font size=\"3\"><span style='color:Black'> This notebook makes use of [earthacess](https://earthaccess.readthedocs.io/en/latest/), [VirtualiZarr](https://virtualizarr.readthedocs.io/en/latest/) and [xarray](https://docs.xarray.dev/en/stable/) to access NASA's cloud files currently on `S3`. [earthacess](https://earthaccess.readthedocs.io/en/latest/) has `built-in` support for accessing OPeNDAP in the Cloud's `DMR++` metadata directly, as opposed to OPeNDAP's Hyrax data server. DMR++ is then to Zarr metadata via [VirtualiZarr](https://virtualizarr.readthedocs.io/en/latest/), providing a huge performance boost for running both locally, or in a Cloud compute environment.\n",
    "\n",
    "<span style='color:#0066cc'><font size=\"3.5\"> **open_virtual_dataset**: \n",
    "\n",
    "[earthacess](https://earthaccess.readthedocs.io/en/latest/) allows data users to convert Hyrax's in the Cloud DMR++ metadata into cloud optimized reference files for the data stored in the cloud. THis is done via:\n",
    "\n",
    "- `earthaccess.open_virtual_dataset`\n",
    "- `earthaccess.open_virtual_mfdataset`\n",
    "\n",
    "\n",
    "<span style='color:#0066cc'><font size=\"3.5\"> **access=\"indirect\" vs access=\"direct\"**: \n",
    "\n",
    "\n",
    "<font size=\"3\"><span style='color:Black'> This tutorial loads data over `https` (`access=\"indirect\"`). However, there is a **significant speed improvement** when using these functions in-cloud and enabling `access=\"direct\"`. This is the case when running this notebook over managed cloud JupyterHubs like [NASA VEDA](https://www.earthdata.nasa.gov/dashboard/) or [2i2c Openscapes](https://workshop.openscapes.2i2c.cloud/hub/login?next=%2Fhub%2F). This is because the data is streamed directly from cloud storage to cloud compute.\n",
    "\n",
    "<span style='color:#ff6666'><font size=\"5\"> **Objectives**\n",
    " \n",
    " \n",
    "- <font size=\"3\"><span style='color:Black'> Demonstrate how to use [earthacess](https://earthaccess.readthedocs.io/en/latest/) to query datasets that are aviable via `OPeNDAP` in the Cloud.\n",
    "- <font size=\"3\"><span style='color:Black'> Demonstrate the use of [earthacess](https://earthaccess.readthedocs.io/en/latest/) to create a virtually aggregated xarray data cube, making use of the Zarr metadata created from DMR++.\n",
    "- <font size=\"3\"><span style='color:Black'> Demonstrate an advanced workflow for storing virtual reference as a Kerchunk object, for later use.\n",
    "\n",
    "\n",
    "<span style='color:#0066cc'><font size=\"3.5\"> **WARNING**: \n",
    "\n",
    "<font size=\"3\"><span style='color:Black'> This feature is current experimental and may change in the future. This feature relies on `NASA` / `OPeNDAP` **DMR++** metadata files which may not always be present for your dataset and you may get a `FileNotFoundError`.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<span style='color:#0066cc'><font size=\"3.5\"> **Additional References**: \n",
    "\n",
    "\n",
    "* This tutorial largely follows: [Cloud optimized access to NASA data with earthaccess and virtualizarr](https://earthaccess.readthedocs.io/en/latest/tutorials/dmrpp-virtualizarr/), available on [earthacess](https://earthaccess.readthedocs.io/en/latest/)'s documentation.\n",
    "\n",
    "* [Nag, Ayush, Gallagher, James. (August, 2024). VirtualiZarr and DMR++. Zenodo. https://doi.org/10.5281/zenodo.13176038](https://doi.org/10.5281/zenodo.13176038).\n",
    "\n",
    "* [Gallagher, James, Yang, Kent, Lee, Hyokyung. (November, 2024). High-Performance Access to Archival Data Stored in HDF4 and HDF5 on Cloud Object Stores Without Reformatting the Files. Zenodo. https://doi.org/10.5281/zenodo.14232491](https://doi.org/10.5281/zenodo.14232491)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac8388c-02aa-4026-93e8-05b3c5cb7c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import earthaccess\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e556c85-3316-4cb2-9b37-ba9114d38e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"`earthaccess` version: \", earthaccess.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39878aed-fb53-49d4-9ea0-ef3bea712f5d",
   "metadata": {},
   "source": [
    "### NASA JPL Multiscale Ultrahigh Resolution (MUR) Sea Surface Temperature (SST) dataset - 0.01 degree resolution\n",
    "\n",
    "We now search for NASA JPL MUR SST data. For that we need\n",
    "- temporal range\n",
    "- Short Name of collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d235f07-39b9-4736-8500-1c62ada34681",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = earthaccess.search_data(\n",
    "    temporal=(\"2010-01-01\", \"2010-01-31\"), short_name=\"MUR-JPL-L4-GLOB-v4.1\"\n",
    ")\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274c89e7-ea70-4210-b497-e64758511f4b",
   "metadata": {},
   "source": [
    "### access DMR++ and create a virtual xarray object\n",
    "we set:\n",
    "- `access=\"indirect\"`: Running this notebook on binder or local machine.\n",
    "- `access=\"direct\"`. Use this when runnnig this notebook on an EC2 instance to make the best use of DMR++, xarray, and DASK.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46871b1b-575d-49a0-abac-8ecb296ad6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mur = earthaccess.open_virtual_mfdataset(\n",
    "    results,\n",
    "    access=\"indirect\",\n",
    "    load=True, # This means Dimensions are loaded into memory\n",
    "    concat_dim=\"time\",\n",
    "    coords=\"all\",\n",
    "    compat=\"override\",\n",
    "    combine_attrs=\"drop_conflicts\",\n",
    ")\n",
    "mur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7007bc94-a167-490d-bd02-2e40aac9a4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This created a virtual reference pointing to \", mur.nbytes/1e9, \"GBs of data on the cloud!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35120686-2211-45c6-a355-47e5d17df483",
   "metadata": {},
   "source": [
    "## We now plot some data\n",
    "\n",
    "<font size=\"3\"><span style='color:Black'> This will actually trigger download / computation of the selected dataset\n",
    "\n",
    "<font size=\"3\"><span style='color:Black'> **NOTE**:\n",
    "\n",
    "* The dimensions are loaded into memory. We can manipulate them \n",
    "* Dimensions are coordinates (not always the case). So we can subset by spatial lat/lon values!!\n",
    "* We can also subset by time (time is a dimension)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f3f96b-7c08-4f8c-977c-f074c05cdc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "spatial_subset = mur.isel(time=0).sel(lat=slice(20, 45), lon=slice(-95, -50))\n",
    "spatial_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e549f1b-17d6-48c9-88a5-0636796c1fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "spatial_subset[\"analysed_sst\"].plot.pcolormesh(x=\"lon\", y=\"lat\", cmap=\"RdBu_r\", figsize=(8, 4));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e1d34b-0c08-4d89-867b-a3089f3d6a16",
   "metadata": {},
   "source": [
    "# A faster workflow:\n",
    "\n",
    "- Set `Load=False`\n",
    "\n",
    "<font size=\"3\"><span style='color:Black'> This creates a virtual reference with only Chunk Manifets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a511969-21c2-4748-a9f5-0d9fdd9706f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mur_vd = earthaccess.open_virtual_mfdataset(\n",
    "    results,\n",
    "    access=\"indirect\",\n",
    "    load=False,\n",
    "    concat_dim=\"time\",\n",
    "    coords=\"all\",\n",
    "    compat=\"override\",\n",
    "    combine_attrs=\"drop_conflicts\",\n",
    ")\n",
    "mur_vd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde97235-d6a3-4df0-a480-c3402d8e6e7f",
   "metadata": {},
   "source": [
    "## Example of what's inside this virtual dataset\n",
    "\n",
    "\n",
    "- `earthaccess` parses OPeNDAP Hyrax's in the Cloud `DMR++`, extracting Chunk References\n",
    "- Creates, using `VirtualiZarr`'s API, a virtual Zarray.\n",
    "- Can then store the Kerchunk Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b32a5f-3ea6-4ada-b54a-278273fe58d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mur_vd.analysed_sst.data.zarray)\n",
    "print(\"\\n\")\n",
    "print(mur_vd.analysed_sst.data.manifest.dict()[\"0.0.1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab24577-259b-47d0-8d02-ffa50911ca3d",
   "metadata": {},
   "source": [
    "## Store as Kerchunk Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb391681-951a-4831-81bf-e38148af5ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mur_vd.virtualize.to_kerchunk(filepath=\"mur_kerchunk.json\", format=\"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cb7a1d-6417-40cd-a217-9dc891157934",
   "metadata": {},
   "source": [
    "## Load using xarray and Kerchunk as engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cf7050-325e-4cbf-8697-198c0cdcdee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fs = earthaccess.get_fsspec_https_session()\n",
    "ds = xr.open_dataset(\n",
    "    \"reference://\",\n",
    "    engine=\"zarr\",\n",
    "    chunks={},\n",
    "    backend_kwargs={\n",
    "        \"consolidated\": False,\n",
    "        \"storage_options\": {\n",
    "            \"fo\": \"mur_kerchunk.json\",\n",
    "            \"remote_protocol\": fs.protocol,\n",
    "            \"remote_options\": fs.storage_options,\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9e0237-a41f-4895-8017-6649b0c4bab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78da4d72-34d8-40da-b74b-111600954ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
