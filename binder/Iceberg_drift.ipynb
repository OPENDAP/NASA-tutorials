{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "731e5668-ca46-44ee-91eb-c644238ff4d2",
   "metadata": {},
   "source": [
    "<span style='color:#0066cc'> <span style='font-family:serif'> <font size=\"6\"> **Access OSCAR Data with OPeNDAP**<span style='color:#0066cc'>\n",
    "\n",
    "<font size=\"3.5\"> Data sources:\n",
    "\n",
    "- [OSCAR](https://podaac.jpl.nasa.gov/dataset/OSCAR_L4_OC_FINAL_V2.0) (Ocean Surface Current Analyses Real-time (OSCAR) Surface Currents - Final 0.25 Degree (Version 2.0)). \n",
    "- Iceberg Data (csv data from Kaggle)\n",
    "\n",
    "\n",
    "<font size=\"3.5\"> This simplified drifter model integrates ocean velocity (from OSCAR) forward in time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494dafce-2280-4d6b-838b-6e2fbba5959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydap.net import create_session\n",
    "from pydap.client import get_cmr_urls, consolidate_metadata, open_url\n",
    "import xarray as xr\n",
    "import datetime as dt\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import earthaccess\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from datetime import timedelta\n",
    "from cftime import DatetimeJulian\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef876a0-c7c0-47ff-b406-5efb59db101d",
   "metadata": {},
   "source": [
    "<span style='font-family:serif'> <font size=\"5.5\"><span style='color:#0066cc'> **Import Token Authorization and create Session**\n",
    " \n",
    "\n",
    "\n",
    "<font size=\"3.5\"> Here we use the Bearer Token to create an authenticated session. For this NASA-specific case, we will use earthaccess.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1582b328-c744-4844-9b17-d15689d3a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = earthaccess.login(strategy=\"interactive\")\n",
    "fs = earthaccess.get_fsspec_https_session()\n",
    "session_kwargs = {'token': fs.storage_options['client_kwargs']['headers']['Authorization'][7:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95feefc9-b239-4c75-8212-8810be0263c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_session = create_session(use_cache=True, session_kwargs=session_kwargs)\n",
    "my_session.cache.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5117ae-23b5-4216-b6aa-6a6a3e5f1fca",
   "metadata": {},
   "source": [
    "<span style='font-family:serif'> <font size=\"5.5\"><span style='color:#0066cc'> **Query opendap urls using NASA's CMR API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c31d252-3e4a-4b53-95f3-7ec940bcee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscar_ccid = \"C2098858642-POCLOUD\" # https://podaac.jpl.nasa.gov/dataset/OSCAR_L4_OC_FINAL_V2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770dbf34-f0e4-4aad-95d1-42d3cd1a44e4",
   "metadata": {},
   "source": [
    "<span style='font-family:serif'> <font size=\"5.5\"><span style='color:#0066cc'> **Filter data via Temporal Searches**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36507ddc-4811-4498-a474-faafaa0a13e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = ['2019-08-16T00:00:00Z', '2020-09-16T00:00:00Z'] # 1 year of data\n",
    "time_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bc012d-7713-43b6-8ce2-6a2e2becc245",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean_urls = get_cmr_urls(ccid=oscar_ccid, time_range=time_range, session=my_session, limit=500)\n",
    "print(\"found: \",len(ocean_urls), \"OSCAR urls\")\n",
    "ocean_urls[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99107c6-6d04-48ef-a51a-8bc1818700b1",
   "metadata": {},
   "source": [
    "<span style='font-family:serif'> <font size=\"5.5\"><span style='color:#0066cc'> **OSCAR data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541c1e09-9865-4160-8e55-f949c02e2628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn urls into DAP4 urls\n",
    "opendap_OSCAR_urls = [url.replace(\"https\", \"dap4\") for url in ocean_urls] # \n",
    "\n",
    "opendap_OSCAR_urls[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dc38d3-301d-4a4c-b704-9309b395d5a4",
   "metadata": {},
   "source": [
    "<span style='font-family:serif'> <font size=\"5.5\"><span style='color:#0066cc'> **Consolidate metadata**\n",
    "\n",
    "<font size=\"3.5\"> All URLs belonging to the same Collection share many identical variables and metadata. The following function\n",
    "reduces redundant metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789554d1-0536-4b85-89b7-98e3e928213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "consolidate_metadata(opendap_OSCAR_urls, concat_dim='time', set_maps=True, session=my_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe91987-06fc-4a60-92de-05f9e52509af",
   "metadata": {},
   "source": [
    "<span style='font-family:serif'> <font size=\"5.5\"><span style='color:#0066cc'> **Create Virtually Aggregated Dataset with Xarray**\n",
    "\n",
    "<font size=\"3.5\"> Now, you can create a virtually aggregated view of the dataset that is ready to analyze with Xarray and Pydap as an engine.\n",
    "\n",
    "`ds_oscar` will contain all relevant ocean data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e418db05-17ab-4888-b09c-6418edcd4fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_oscar = xr.open_mfdataset(opendap_OSCAR_urls, engine='pydap', session=my_session, combine='nested', concat_dim=\"time\", chunks={'latitude': 300})\n",
    "ds_oscar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9007adf-0292-4e7d-ad8f-521984f464f5",
   "metadata": {},
   "source": [
    "<span style='font-family:serif'> <font size=\"5.5\"><span style='color:#0066cc'> **Download only a subset of data and store locally**\n",
    "\n",
    "<font size=\"3.5\"> The dimensions `latitude`, `longitude` do not match the name of the coordinates, despite both being 1D arrays. However, to use these we can load the coordinates `lat` and `lon`  into memory and query the indexes longitude and latitude that match our coordinates of interest.\n",
    "\n",
    "<font size=\"3.5\"> We will need:\n",
    "- <font size=\"3.5\"> Load `lat`, `lon` into memory, using the xarray `.load()` method\n",
    "- <font size=\"3.5\"> Identify the range of `longitude` and `latitude` that match our subset, and the indexes associated with these.\n",
    "- <font size=\"3.5\"> Download only that data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380b4a30-3f8a-4039-af41-53df13b63b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_oscar['lon'], ds_oscar['lat'] = ds_oscar['lon'].load(), ds_oscar['lat'].load()\n",
    "ds_oscar = ds_oscar.rename_vars({'lon':'longitude', 'lat':'latitude'}).set_index(longitude='longitude').set_index(latitude='latitude').drop_vars(['ug', 'vg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72297269-85de-41d7-b5e8-0cf323f16d44",
   "metadata": {},
   "source": [
    "### visualize subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf608263-33b0-428d-bbfd-8b968def5b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 10), subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "\n",
    "# Add filled land background\n",
    "ax.add_feature(cfeature.LAND, facecolor='black', zorder=0)\n",
    "\n",
    "cbar_kwargs={\n",
    "        'shrink': 0.2,        # reduce height\n",
    "        'aspect': 10,         # width-to-height ratio\n",
    "        'pad': 0.05,          # spacing from the main plot\n",
    "        'label': 'Zonal Velocity (m/s)'  # optional label\n",
    "    }\n",
    "\n",
    "# Plot ocean data on top\n",
    "ds_oscar['u'].isel(time=0, latitude=slice(40, 300)).transpose().plot(ax=ax, transform=ccrs.PlateCarree(), cmap='hsv', cbar_kwargs=cbar_kwargs)\n",
    "ax.coastlines()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aa1762-f989-4445-945e-1b7b8cfe98cd",
   "metadata": {},
   "source": [
    "## before downloding: re-chunk!\n",
    "\n",
    "Rechunking instructs the Hyrax OPeNDAP server via xarray to download only those chunks at a time. This enables to construct a constraint expression via pydap, to request Hyrax  only that size of download \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c1475d-6538-49cf-bd5c-1913e8fb0288",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_oscar.isel(latitude=slice(40, 300)).to_netcdf(\"./data/Oscar_data.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d68c0b9-6be0-4fe5-b88a-4a9f7500e127",
   "metadata": {},
   "source": [
    "## Now that data is downloaded..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c315fd-90ca-43df-89b0-9711889fcec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data\"\n",
    "csv_files = sorted(glob.glob(os.path.join(path, \"*.csv\")))\n",
    "dates = []\n",
    "Coords = []\n",
    "Times = []\n",
    "DFs = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    df = df[~df['Remarks'].str.contains(\"grounded\", na=False)]\n",
    "    # DFs.append(df)\n",
    "    times = len(df.index)*[dt.datetime.strptime((\"-\").join(df[\"Last Update\"].values[0].split(\"/\")), \"%m-%d-%Y\").strftime(\"%Y-%m-%dT%H:%M:%SZ\")]\n",
    "    Time = pd.DataFrame(times, columns=['time'], index=df.index)\n",
    "    df['Date']=Time\n",
    "df = df.drop(columns=['Remarks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab60be11-34ee-4398-8243-562d28717a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "drifters = df\n",
    "drifters.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cabc7e7-f6b5-436f-9ec8-b5c4643f2dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscar_path = './data/Oscar_data.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c9046f-39b3-4a02-80ad-50eadad6d73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ovels = xr.open_dataset(oscar_path) # ocean velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5fb7f6-f258-4bfb-a388-2daaedacf7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_model(t, _Lats, _Lons, u, v):\n",
    "    # sample all points from source data, using nearest neighbor (default)\n",
    "    dt_seconds = 86400  # 1 day in seconds\n",
    "    u0, v0 = u.sel(time=np.array(t)), v.sel(time=np.array(t))\n",
    "    indexer = {\n",
    "        \"latitude\": xr.DataArray(_Lats, dims=\"location\"),\n",
    "        \"longitude\": xr.DataArray(_Lons, dims=\"location\"),\n",
    "    }\n",
    "    # Will assume these are in water, and nan -> 0 velocity\n",
    "    nan_to_value = 0\n",
    "    u_vals = u0.sel(**indexer, method='nearest').fillna(nan_to_value)\n",
    "    v_vals = v0.sel(**indexer, method='nearest').fillna(nan_to_value)\n",
    "\n",
    "    # Approximate degrees per meter\n",
    "    lat_per_m = 1 / 111320\n",
    "    lon_per_m = 1 / (111320 * np.cos(np.radians(_Lats)))\n",
    "\n",
    "    # Update position due to velocity drift and wind-driven ekman\n",
    "    # Approximation for large icebers with weak wind forcing\n",
    "\n",
    "    nlat = v_vals * dt_seconds * lat_per_m\n",
    "    nlon = u_vals * dt_seconds * lon_per_m\n",
    "    \n",
    "    nlat, nlon = nlat.rename('delta_lat'), nlon.rename('delta_lon')\n",
    "    ncoords = pd.merge(nlat.to_dataframe(), nlon.to_dataframe()[['delta_lon']],left_index=True, right_index=True)\n",
    "\n",
    "    # Use the input latitudes to update the output data\n",
    "    ncoords['latitude'] = indexer['latitude'] +  ncoords['delta_lat']\n",
    "    ncoords['longitude'] = indexer['longitude'] + ncoords['delta_lon']\n",
    "    vels = pd.merge(u_vals.to_dataframe(), v_vals.to_dataframe())[['v', 'u']]\n",
    "    # \n",
    "    return pd.concat([ncoords, vels], axis=1)[['time', 'latitude', 'longitude', 'v', 'u']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7817149f-210a-4039-a5ef-f1c731c3da45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e6588e-3484-4db8-a5dd-9c75315e3236",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = timedelta(days=1)\n",
    "results = []\n",
    "# initial condition\n",
    "time, Lats, Lons = drifters['Date'].values[0], drifters['Latitude'].values, drifters['Longitude'].values\n",
    "# Parse into pandas Timestamp first\n",
    "t_pd = pd.Timestamp(time)\n",
    "t = DatetimeJulian(t_pd.year, t_pd.month, t_pd.day, t_pd.hour, t_pd.minute, t_pd.second)\n",
    "Time=[]\n",
    "for n in range(ds_ovels.time.shape[0]-1):\n",
    "    results.append(forward_model(t, Lats, Lons, ds_ovels['u'], ds_ovels['v']))\n",
    "    t += dt\n",
    "    Time.append(t)\n",
    "    Lats, Lons = results[-1]['latitude'].values, results[n]['longitude'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9d7d63-d424-4357-9e63-8ca233033586",
   "metadata": {},
   "source": [
    "# create an xarray dataset with the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117aadec-d20e-41f7-ae48-61d2e1124c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pds = [results[n].drop(columns=['time']) for n in range(len(results))]\n",
    "drifts = xr.concat([pds[n].to_xarray() for n in range(len(pds))], dim='time')\n",
    "drifts['time']=xr.DataArray(data=Time, dims='time')\n",
    "drifts = drifts.rename_dims({'index': 'iceberg'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabd1dbc-9d5e-4fd9-9941-165281068ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "drifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a63d300-68d9-44ff-9357-2b294e8d2ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Projection centered on South Pole\n",
    "proj = ccrs.SouthPolarStereo()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = plt.subplot(1, 1, 1, projection=proj)\n",
    "\n",
    "# Set extent: South Pole to ~40°S\n",
    "ax.set_extent([-180, 180, -90, -40], crs=ccrs.PlateCarree())\n",
    "ax.add_feature(cfeature.LAND, facecolor='black')\n",
    "\n",
    "# Add coastlines and grid\n",
    "ax.coastlines(resolution='110m')\n",
    "ax.gridlines(draw_labels=True)\n",
    "\n",
    "# Plot each drifter as a trajectory\n",
    "# for i in drifts.iceberg.data:  # loop over drifters\n",
    "for i in range(0, 7):\n",
    "    lons = drifts['longitude'].isel(iceberg=i).data\n",
    "    lats = drifts['latitude'].isel(iceberg=i).data\n",
    "    u0, v0 = drifts['u'].isel(iceberg=i).data, drifts['v'].isel(iceberg=i).data\n",
    "\n",
    "    ax.plot(\n",
    "        lons,\n",
    "        lats,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        label=drifters['Iceberg'].values[i],\n",
    "        linewidth=6\n",
    "    )\n",
    "    ax.plot(\n",
    "        lons[0],\n",
    "        lats[0],\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        marker='s',\n",
    "        color='k'\n",
    "    )\n",
    "    ax.quiver(lons, lats, u0, v0, transform=ccrs.PlateCarree(), color='gray', scale=3, scale_units='width')\n",
    "\n",
    "plt.title(\"Drifter Trajectories near Antarctica\")\n",
    "plt.legend(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e12f1fc-1315-4561-b327-1bab44879ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
